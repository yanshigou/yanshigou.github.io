---
title: "python最火爬虫框架Scrapy入门"
date: 2019-01-16 15:59
author: dzt
subtitle:  Scrapy、MongoDB、豆瓣电影
tags:
  - scrapy
  - study
  - mongodb
  - 爬虫
---

## 前言
**Scrapy，Python开发的一个快速,高层次的web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。任何人都可以根据需求方便的修改。**

**Scrapy是一套基于Twisted的异步处理框架，是纯python实现的爬虫框架，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，用来抓取网页内容或者各种图片**



## 环境

* python3.6.5 64位
* win10 64位



## 安装

**1.cmd中进入虚拟环境**

> 这个不再过多说明
> 
> **pip install scrapy**

报出如下错误：

```
    error: Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ Build Tools": https://visualstudio.microsoft.com/downloads/

    ----------------------------------------
Command "d:\virtualenv\scrapy_py3\scripts\python3.exe -u -c "import setuptools, tokenize;__file__='C:\\Users\\shenz\\AppData\\Local\\Temp\\pip-install-bto36w94\\Twisted\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))" install --record C:\Users\shenz\AppData\Local\Temp\pip-record-dx1n8s3h\install-record.txt --single-version-externally-managed --compile --install-headers d:\virtualenv\scrapy_py3\include\site\python3.6\Twisted" failed with error code 1 in C:\Users\shenz\AppData\Local\Temp\pip-install-bto36w94\Twisted\
```

### 解决

1. 通过[Unofficial Windows Binaries for Python Extension Packages](http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted)下载twisted对应版本的whl文件。

> 我的为Twisted-18.4.0-cp36-cp36m-win_amd64.whl

2. 运行命令：`pip install Twisted-18.4.0-cp36-cp36m-win_amd64.whl`

>注意路径

4. 再次进行 `pip install scrapy` 即可



**2.cmd中输入scrapy**

> scrapy

```
(scrapy_py3) D:\virtualenv\scrapy_py3\Scripts>scrapy
Scrapy 1.5.1 - no active project

Usage:
  scrapy <command> [options] [args]

Available commands:
  bench         Run quick benchmark test
  fetch         Fetch a URL using the Scrapy downloader
  genspider     Generate new spider using pre-defined templates
  runspider     Run a self-contained spider (without creating a project)
  settings      Get settings values
  shell         Interactive scraping console
  startproject  Create new project
  version       Print Scrapy version
  view          Open URL in browser, as seen by Scrapy

  [ more ]      More commands available when run from project directory

Use "scrapy <command> -h" to see more info about a command
```

出现**Scrapy 1.5.1 - no active project**就表示安装成功



## 安装MongoDB

**1.在官网上下载**[https://www.mongodb.com/download-center/community](https://www.mongodb.com/download-center/community)

> 我使用的是3.6.9 windows 64-bit x64  MSI

**2.下载完成后双击安装，过程中去掉 Install MongoDB Compass**

**3.创建数据目录和日志目录**

```
mkdir mongodb
cd mongodb
mkdir log 
```



### 测试连接

**运行MongoDB服务器**

```
C:\Program Files\MongoDB\Server\3.6\bin>mongod --dbpath d:mongodb
2019-01-16T01:05:56.968-0700 I CONTROL  [initandlisten] MongoDB starting : pid=21012 port=27017 dbpath=d:mongodb 64-bit host=DESKTOP-JP2T8KQ
2019-01-16T01:05:56.968-0700 I CONTROL  [initandlisten] targetMinOS: Windows 7/Windows Server 2008 R2
2019-01-16T01:05:56.969-0700 I CONTROL  [initandlisten] db version v3.6.9
```

> 大概是这个样子 省略了很多

**再新开一个命令终端**

```
C:\Program Files\MongoDB\Server\3.6\bin>mongo.exe
MongoDB shell version v3.6.9
connecting to: mongodb://127.0.0.1:27017
xxx
> exit
bye
```

> 中间也省略了很多
>
> 出现> 表示连接成功 输入exit 退出



### 配置MongoDB的Windows服务

> 当mongod.exe被关闭时，mongo.exe 就无法连接到数据库了，因此每次想使用mongodb数据库都要开启mongod.exe程序，所以比较麻烦，此时我们可以将MongoDB安装为windows服务

**在终端输入**

> 需要使用管理员权限
>
> 配置db路径和log路径
>
> 先在log文件夹下创建一个mongdb.log

```
C:\Program Files\MongoDB\Server\3.6\bin>mongod.exe --dbpath "d:\mongodb\db" --logpath "d:\mongodb\log\mongdb.log" --install --serviceName MongoDB
```

**启动服务**

```
C:\Program Files\MongoDB\Server\3.6\bin>net start MongoDB
MongoDB 服务正在启动 ..
MongoDB 服务已经启动成功。
```

**连接MongoDB**

```
C:\Program Files\MongoDB\Server\3.6\bin>mongo
MongoDB shell version v3.6.9
connecting to: mongodb://127.0.0.1:27017
Implicit session: session { "id" : UUID("b178b4c8-cba2-4886-8e7c-b9958e839b0d") }
MongoDB server version: 3.6.9
> show dbs
admin   0.000GB
config  0.000GB
local   0.000GB
> exit
bye
```

**关闭服务**

```
C:\Program Files\MongoDB\Server\3.6\bin>net stop MongoDB
MongoDB 服务正在停止.
MongoDB 服务已成功停止。
```

**删除进程**

```
C:\Program Files\MongoDB\Server\3.6\bin>mongod.exe --dbpath "d:\mongodb\db" --logpath "d:\mongodb\log\mongdb.log" --remove --serviceName MongoDB
```


### 配置环境变量

右键我的电脑 > 高级系统设置 > 环境变量 > 系统变量 > Path > 新建添加 C:\Program Files\MongoDB\Server\3.6\bin

然后新开一个终端

直接使用mongo 能进入 表明配置成功



## 使用 no sql manager for mongodb windows 可视化工具

我的版本：

> | Product							    | Version  |	Release		 |	Size	      |
> | NoSQL Manager for MongoDB Freeware | 4.10.0.4 | January 14, 2019  | 34 MByte |

使用默认设置，连接本地MongoDB

![](https://raw.githubusercontent.com/yanshigou/yanshigou.github.io/master/img/t/mongodb.png)

连接成功

![](https://raw.githubusercontent.com/yanshigou/yanshigou.github.io/master/img/t/mongodb1.png)





## 创建项目

**进入命令终端，虚拟环境**

```
(scrapy_py3) D:\dzt>scrapy startproject douban
New Scrapy project 'douban', using template directory 'd:\\virtualenv\\scrapy_py3\\lib\\site-packages\\scrapy\\templates\\project', created in:
    D:\dzt\douban

You can start your first spider with:
    cd douban
    scrapy genspider example example.com
```

**使用pycharm打开项目**

![](https://raw.githubusercontent.com/yanshigou/yanshigou.github.io/master/img/t/douban.png)

**再回到终端**

> 创建爬虫文件douban_spider 和 路径movie.douban.com （豆瓣电影）

```
(scrapy_py3) D:\dzt\douban>cd douban\spiders

(scrapy_py3) D:\dzt\douban\douban\spiders>scrapy genspider douban_spider movie.douban.com
Created spider 'douban_spider' using template 'basic' in module:
  douban.spiders.douban_spider
```

![](https://raw.githubusercontent.com/yanshigou/yanshigou.github.io/master/img/t/douban.png)

**第一步就完成了**



## 编写项目

### 修改itmes.py

```python
# -*- coding: utf-8 -*-

# Define here the models for your scraped items
#
# See documentation in:
# https://doc.scrapy.org/en/latest/topics/items.html

import scrapy


class DoubanItem(scrapy.Item):
    # define the fields for your item here like:
    # name = scrapy.Field()
    # 序号 电影名称 电影介绍 星级 电影评论数 电影描述
    serial_number = scrapy.Field()
    movie_name = scrapy.Field()
    introduce = scrapy.Field()
    star = scrapy.Field()
    evaluate = scrapy.Field()
    describe = scrapy.Field()

```



### spider 编写

